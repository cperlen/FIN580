---
title: "FIN580_Final"
output: pdf_document
---

#installing needed packages
```{r, warning=FALSE,tidy=TRUE, message=FALSE }
#Setup 
library(xlsx)
library(forecast)
library(tseries)
library(stats)
library(car)
library(glmnet)
library(miscTools)
library(Metrics)
library(knitr)
library(class)
library(vars)
library(stargazer)
library(fGarch)
library(orderedLasso)
library(depmixS4)

#Set seed
set.seed(1560)

```
---
  
Reading in and preprocessing data. Changing Train to be sequential for GARCH modeling. This new data is at the bottom of the this chunk of code - please load the appropriate files.
```{r, warning=FALSE,tidy=TRUE, message=FALSE }

#setwd("~/Desktop/FIN580/data")
setwd("~/Documents/Grad_School/2016-2017_Spring/Amin/Homework/HW_3/FIN580/data") #Nina's
load_data_from_scratch = F


if(load_data_from_scratch){
  file_names=dir(path="~/Desktop/FIN580/data",pattern = '.csv')
  currencies = strsplit(file_names[1:(length(file_names)-1)],'USD.csv')
  labels = read.csv(file_names[length(file_names)],header = T)
  labels[,1] = as.Date(labels[,1], origin = lubridate::origin )
  labels[nrow(labels),2] = 0 #not training on last day because do not have data to test fit
  colnames(labels)[1] = "Date"
  
  prices = lapply(file_names[1:length(currencies)], function(x) { 
    temp = read.csv(x ,header = T)
    temp = temp[,c("Date","Close")]
    if(x == "AUDUSD.csv"){
      temp$Date = as.Date(temp$Date, format = "%m/%d/%y",origin = lubridate::origin) #why it has a different format I have no idea
    }
    else{
      temp$Date = as.Date(temp$Date, format = "%m/%d/%Y",origin = lubridate::origin)
    }
    return(temp) })
  
  names(prices) = currencies
  dates = unique(labels[,1])
  
  #compute return series
  get_5min_rets = function(x){
    tot_rets = data.frame(Date=as.Date(character()), Returns = numeric())
    pos = 1
    for(i in 1:length(dates)){
      indicies = which(x[,1] == dates[i])
      if(length(indicies) != 0){
        
        daily_prices = x[indicies,2]
        daily_rets = log(daily_prices[2:length(daily_prices)]/daily_prices[1:(length(daily_prices)-1)])
        len = length(daily_rets)
        tot_rets[pos:(pos+len-1),] = list(rep(dates[i],length(daily_rets)),daily_rets)
        pos = pos + len
      }
    }
    return(tot_rets)
  }
  
  rets_5min = lapply(prices, get_5min_rets)
  
  get_daily_rets = function(x){
    rets = data.frame(Date=as.Date(character()), Ret = numeric(), Train = numeric() )
    pos = 1
    for(i in 1:length(dates)){
      indicies = which(x[,1] == dates[i])
      len = length(indicies)
      if(len != 0){
        ret = log(x[indicies[len],2]/x[indicies[1],2]) #return for the day is log(P_23:55/P_0:00)
        rets[pos,] = list(dates[i],ret, labels[which(labels$Date == dates[i]),2])
        pos = pos + 1
      }
    }
    return(rets)
  }
  
  daily_rets = lapply(prices, get_daily_rets)
  
  
  
  #compute volatility series
  
  get_daily_vols = function(x){
    
    vols = data.frame(Date=as.Date(character()), Vol = numeric(), Train = numeric() )
    pos = 1
    for(i in 1:length(dates)){
      indicies = which(x[,1] == dates[i])
      if(length(indicies) != 0){
        rets = x[indicies,2]
        vol = sqrt(252) * sd(rets) #annualize volatility
        if(vol != 0){ #get rid of days during which vol is 0
          vols[pos,] = list(dates[i],log(vol), labels[which(labels$Date == dates[i]),2])
          pos = pos + 1
        }
      }
    }
    return(vols)
  }
  
  daily_vols = lapply(rets_5min,get_daily_vols)
  
  
  #weekly statics
  dates_by_curr = lapply(daily_vols, function(x){ x$Date}) #which dates have non-zero vols
  
  
  
  get_weekly_vols = function(curr){
    x = rets_5min[[curr]]
    c_dates = dates_by_curr[[curr]]
    
    vols = data.frame(Date=as.Date(character()), Vol = numeric(), Train = numeric() )
    pos = 1
    i = 1
    while(i <= length(c_dates)-5){
      indicies = unique(unlist(sapply(i:(i+4), function(j) { which(x[,1] == c_dates[j])})))
      if(length(indicies) != 0){
        rets = x[indicies,2]
        vol = sqrt(50) * sd(rets) #annualize volatility
        if(vol != 0){ #get rid of days during which vol is 0
          vols[pos,] = list(c_dates[i],log(vol), labels[which(labels$Date == c_dates[i]),2])
          pos = pos + 1
        }
      }
      i = i + 5 
    }
    return(vols)
  }
  
  weekly_vols = lapply(currencies, get_weekly_vols)
  names(weekly_vols) = currencies
  
  
  
  get_weekly_rets = function(curr){
    x = prices[[curr]]
    c_dates = dates_by_curr[[curr]]
    
    rets = data.frame(Date=as.Date(character()), Ret = numeric(), Train = numeric() )
    pos = 1
    i = 1
    while(i <= length(c_dates)-5){
      indicies = unique(unlist(sapply(i:(i+4), function(j) { which(x[,1] == c_dates[j])})))
      n = length(indicies)
      if(n != 0){
        ret = log(x[indicies[n],2] / x[indicies[1],2] )#last day close divided first day open
        rets[pos,] = list(c_dates[i],ret, labels[which(labels$Date == c_dates[i]),2]) 
        pos = pos + 1
      }
      i = i + 5
    }
    return(rets)
  }
  
  weekly_rets = lapply(currencies, get_weekly_rets)
  names(weekly_rets) = currencies
  
  append_target = function(ts){
    for(curr in currencies){
      temp = ts[[curr]]
      len = nrow(ts[[curr]])
      ts[[curr]] = ts[[curr]][1:(len-1),]
      ts[[curr]] [,'Target'] = temp[2:len,2] 
    }
    return(ts)
  }
  
  append_ret = function(ts,rets){
    for(curr in currencies){
      dates = ts[[curr]]$Date
      ret = rets[[curr]]
      pos = 1
      for(d in dates){
        lookup = which(ret[,1]== as.Date(d,lubridate::origin))
        ts[[curr]][pos,'Ret'] = ret$Ret[lookup]
        pos = pos + 1
      }
    }
    return(ts)
  }
  
  append_label = function(ts,rets){
    for(curr in currencies){
      series = ts[[curr]]
      labels = sapply(1:nrow(series),function(i){
        s = sign(series$Target[i] - series$Vol[i])
        if(s == 0){ #break ties
          s = 1
        }
        return(s)} )
      ts[[curr]]['Y(t)'] = labels
    }
    return(ts)
  }
  
  
  daily_data = append_target(daily_vols)
  weekly_data = append_target(weekly_vols)
  daily_data = append_ret(daily_data,daily_rets)
  weekly_data = append_ret(weekly_data,weekly_rets)
  daily_data = append_label(daily_data)
  weekly_data = append_label(weekly_data)
  
  #remove JPY and SEK
  currencies = currencies[-6] 
  currencies = currencies[-8]
  weekly_data = weekly_data[-6]
  weekly_data = weekly_data[-8]
  daily_data = daily_data[-6]
  daily_data = daily_data[-8]
  
  save(weekly_data, file = "weekly_data.Rdata")
  save(daily_data,file = "daily_data.Rdata")
  save(currencies, file = "currencies.RData")
  
  
  
  
}
if(!load_data_from_scratch)  {
  load("weekly_data.Rdata")
  load("daily_data.Rdata")
  load("currencies.RData")
}

#Changing train to sequential ####
n=nrow(daily_data[[1]])
new_train=c(rep(1,n*(3/5)),rep(0,n-(n*3/5)+1))
old_names=colnames(daily_data[[1]])
names=c(old_names,"S_Train")

daily_data=lapply(seq(1,length(currencies),1), function(i){
  n=nrow(daily_data[[i]])
  S_train=c(rep(1,n*(3/5)),rep(0,n-(n*3/5)+1))
  daily_data[[i]]=cbind(daily_data[[i]],S_train)
})

weekly_data=lapply(seq(1,length(currencies),1), function(i){
  n=nrow(weekly_data[[i]])
  S_train=c(rep(1,n*(3/5)),rep(0,n-(n*3/5)))
  weekly_data[[i]]=cbind(weekly_data[[i]],S_train)
})

setwd("~/Documents/Grad_School/2016-2017_Spring/Amin/Homework/HW_3/FIN580/final/data")
save(daily_data, file="daily_data_final.RData")
save(weekly_data, file="weekly_data_final.RData")

#Final data used - Please load this ###########
setwd("~/Documents/Grad_School/2016-2017_Spring/Amin/Homework/HW_3/FIN580/final/data")
load("daily_data_final.RData")
load("weekly_data_final.RData")
```

Step 2: Model Fitting
For model fitting we fit two types of models: GARCH and ordered Lasso. 

For comparison we will fit a GARCH to compare MSE to our regime splitting method. Here we have a generic garch fit model which returns testing error. 
```{r,warning=FALSE,tidy=TRUE,message=FALSE}
#Data type is "daily" or "weekly"
#And curr_i is the currency index
#Returns test error
garch_stats=function(data_type,curr_i){
  use_data=get(paste(data_type,"_data",sep=""))[[curr_i]]
  train=use_data[which(use_data[,"S_train"]==1),"Ret"]
  test=use_data[which(use_data[,"S_train"]==0),"Vol"]
  model=garchFit(formula=~garch(1,1),data=train,verbose=FALSE)
  pred_y=predict(model,n.ahead=length(test))$standardDeviation
  #Since we have log-vols, but the predictions arent need to change
  pred_y=log(pred_y)
  return(mse(pred_y,test))
}

#Get stats for using just one garch as a baseline comparison
mse_garch_all_daily=sapply(seq(1,length(currencies),1), function(x){ garch_stats("daily",x)})

mse_garch_all_weekly=sapply(seq(1,length(currencies),1), function(x){ garch_stats("weekly",x)})

#Table for presentation - we will overwrite pres_table consistently throughout
#Tables output into Latex
pres_table=cbind(mse_garch_all_daily,mse_garch_all_weekly)
means=c(mean(mse_garch_all_daily),mean(mse_garch_all_weekly))
pres_table=rbind(pres_table,means)
colnames(pres_table)=c("Daily","Weekly")
rownames(pres_table)=c(currencies,"Average")
stargazer(pres_table)
```


For comparison we will fit an ordered lasso to compare MSE to our regime splitting method. Here we have a generic ordered lasso fit model which returns testing error. 
```{r,warning=FALSE,tidy=TRUE,message=FALSE}
#Data type is "daily" or "weekly"
#And curr_i is the currency index
#We use cross validation for parameter selection 
#Returns test error
#p is max lag - we will also optimize over this
lasso_stats=function(data_type,curr_i,p){
  use_data=get(paste(data_type,"_data",sep=""))[[curr_i]]
  #Training x and y 
  train_x=use_data[which(use_data[,"S_train"]==1),"Vol"]
  train_x=data.matrix(train_x[-length(train_x)])
  train_y=use_data[which(use_data[,"S_train"]==1),"Vol"]
  train_y=train_y[-1]
  #Testing x and y 
  test_x=use_data[which(use_data[,"S_train"]==0),"Vol"]
  test_x=data.matrix(test_x[-length(test_x)])
  test_y=use_data[which(use_data[,"S_train"]==0),"Vol"]
  test_y=data.matrix(test_y[-1])
  #Cross validation model - we enforce strong ordering
  cvmodel=timeLagLasso.cv(train_x,train_y,maxlag=p,strongly.ordered = TRUE,trace=FALSE)
  lam=cvmodel$lamhat
  model=timeLagLasso(train_x,train_y,lambda=lam,maxlag=p,strongly.ordered = TRUE,trace=FALSE)
  pred_y=predict.timeLagLasso(model,test_x)
  pred_y=pred_y$yhat.ordered[1:length(test_y)]
  #Since we need to also optimize over p we return testing error and training error
  return(c(min(cvmodel$cv.err),mse(pred_y,test_y)))
}

ave_lassos=function(data_type,p){
  errs=sapply(seq(1,length(currencies),1),function(x){lasso_stats(data_type,x,p)})
  return(rowMeans(data.matrix(errs)))
}

lasso_stats("daily",1,3)
ave_lassos("daily",2)

ps=seq(2,6,1)
mses_lasso_daily=sapply(ps,function(x){ave_lassos("daily",x)})
mses_lasso_weekly=sapply(ps,function(x){ave_lassos("weekly",x)})

#Table for presentation - we will overwrite pres_table consistently throughout
#Tables output into Latex
i_d=which.min(mses_lasso_daily[1,])
i_w=which.min(mses_lasso_weekly[1,])
pres_table=cbind(ps[i_d],ps[i_w])
pres_table=rbind(pres_table,c(mses_lasso_daily[2,i_d],mses_lasso_weekly[2,i_w]))
colnames(pres_table)=c("Daily","Weekly")
rownames(pres_table)=c("Max lag","Out of sample error")
stargazer(pres_table)
```

Step 1: Regime switching

We now turn to the regime switching aspect of things. The following code is VERY time consuming to run - I recommed loaded the already run results located in the data folder. For convenience I put them at the beginning of the code chunk.
```{r,warning=FALSE,tidy=TRUE,message=FALSE}
#Use these unless you want to spend ~4-5 hrs watching code run. 
setwd("~/Documents/Grad_School/2016-2017_Spring/Amin/Homework/HW_3/FIN580/final/data")
load("Daily_test_regimes_2.RData")
load("Daily_test_regimes_3.RData")
load("Weekly_test_regimes_2.RData")
load("Weekly_test_regimes_3.RData")

#This is the actual code used to acquire the results

#For outputting purposes we show that the regime model looks like on just the train data
#Daily
for(i in 1:length(currencies)){}

#Plots and saves HMM on train data for each currency
#We also save the states for tarin only for each model so we can build models for them


plot_hmm_train=function(i,n_states){
  names=c("Regime 1","Regime 2")
  if(n_states>2){
    names=c(names,"Regime 3")
  }
  #Daily
  use_data=daily_data[[curr_i]]
  data=use_data[which(use_data[,"S_train"]==1),]
  hmm=depmix(Vol~1,family=gaussian(),nstates=n_states,data=data)
  hmm_fit=fit(hmm,verbose=FALSE)
  post_probs=posterior(hmm_fit)
  daily_states=data.frame(post_probs$state)
  pdf(paste(currencies[i],"_TR_daily.pdf",sep=""), onefile=T, paper='A4r')
  plot(data$Date,post_probs$state, type='s', main='True Regimes - Daily', xlab='', ylab='Regime')
  dev.off()
   pdf(paste(currencies[i],"_TR_pp_daily.pdf",sep=""), onefile=T, paper='A4r')
  matplot(post_probs[,-1], type='l', main='Regime Posterior Probabilities - Daily', ylab='Probability')
  legend(x='topright', legend=names, fill=1:n_states, bty='n')
  dev.off()
  
  #Weekly
  use_data=weekly_data[[curr_i]]
  data=use_data[which(use_data[,"S_train"]==1),]
  hmm=depmix(Vol~1,family=gaussian(),nstates=n_states,data=data)
  hmm_fit=fit(hmm,verbose=FALSE)
  post_probs=posterior(hmm_fit)
  weekly_states=data.frame(post_probs$state)
  pdf(paste(currencies[i],"_TR_weekly.pdf",sep=""), onefile=T, paper='A4r')
  plot(data$Date,post_probs$state, type='s', main='True Regimes - Weekly', xlab='', ylab='Regime')
  dev.off()
   pdf(paste(currencies[i],"_TR_pp_weekly.pdf",sep=""), onefile=T, paper='A4r')
  matplot(post_probs[,-1], type='l', main='Regime Posterior Probabilities - Weekly', ylab='Probability')
  legend(x='topright', legend=names, fill=1:n_states, bty='n')
  dev.off()
  return(list(daily_states,weekly_states))
}

setwd("~/Documents/Grad_School/2016-2017_Spring/Amin/Homework/HW_3/FIN580/final/plots")
daily_states_2=list()
weekly_states_2=list()
daily_states_3=list()
weekly_states_3=list()
for(i in 1:length(currencies)){
  temp=plot_hmm_train(i,2)
  daily_states_2[length(daily_states_2)+1]=temp[[1]]
  weekly_states_2[length(weekly_states_2)+1]=temp[[2]]
  temp=plot_hmm_train(i,3)
  daily_states_3[length(daily_states_3)+1]=temp[[1]]
  weekly_states_3[length(weekly_states_3)+1]=temp[[2]]
}

setwd("~/Documents/Grad_School/2016-2017_Spring/Amin/Homework/HW_3/FIN580/final/data")
save(daily_states_2,file="Daily_states_train_2.RData")
save(weekly_states_2,file="Weekly_states_train_2.RData")
save(daily_states_3,file="Daily_states_train_3.RData")
save(weekly_states_3,file="Weekly_states_train_3.RData")


#There is no real "predict" function - instead we use an expanding window to fit an HMM to all the data including the current test value and then we get the final state
#end_i is the end of the testing data set where the current point is
#Since we hope to be able to try both 2 and 3 states, we include n_states as an input for flexibility purposes
#We assume data is Gaussian
get_regime=function(use_data,end_i,n_states){
  #Data getting
  data=use_data[which(use_data[,"S_train"]==1),]
  add=use_data[which(use_data[,"S_train"]==0),]
  add=add[1:end_i,]
  data=rbind(data,add)
  #Model fitting
  hmm=depmix(Vol~1,family=gaussian(),nstates=n_states,data=data)
  hmm_fit=fit(hmm,verbose=FALSE)
  post_probs=posterior(hmm_fit)
  return(post_probs$state[length(post_probs$state)])
}

#This function run returns a full set of train states for a currencie
get_train_regimes=function(data_type,curr_i,n_states){
  use_data=get(paste(data_type,"_data",sep=""))[[curr_i]]
  train_n=length(use_data[which(use_data[,"S_train"]==0),"Vol"])
  train_regimes=sapply(seq(1,train_n,1),function(x){
    print(x)
    print(currencies[[curr_i]])
    get_regime(use_data,x,n_states)}
    )
  return(train_regimes)
}

daily_test_regimes_2=list()
daily_test_regimes_3=list()
weekly_test_regimes_2=list()
weekly_test_regimes_3=list()
#For some reason can only run 4 sets in the 4 loop (hehe bc it's a four loop get it- but actually it breaks down) then you have to run one by one, don't argue with the computer just give in
for(i in 1:length(currencies)){
  #Daily
  daily_test_regimes_2[length(daily_test_regimes_2)+1]=data.frame(get_train_regimes("daily",i,2))
    daily_test_regimes_3[length(daily_test_regimes_3)+1]=data.frame(get_train_regimes("daily",i,3))
    #Weekly
    weekly_test_regimes_2[length(weekly_test_regimes_2)+1]=data.frame(get_train_regimes("weekly",i,2))
    weekly_test_regimes_3[length(weekly_test_regimes_3)+1]=data.frame(get_train_regimes("weekly",i,3))
}

setwd("~/Documents/Grad_School/2016-2017_Spring/Amin/Homework/HW_3/FIN580/final/data")
save(daily_test_regimes_2,file="Daily_test_regimes_2.RData")
save(daily_test_regimes_3,file="Daily_test_regimes_3.RData")
save(weekly_test_regimes_2,file="Weekly_test_regimes_2.RData")
save(weekly_test_regimes_3,file="Weekly_test_regimes_3.RData")
```

Step 2: Models by regime. We use the regimes on the training data to fit models on the trading data for each regime. Then we apply the relevant model to the testing data based on the testing regime.

Naming convention for models is as follows: model_d/w_num. of regimes_regime num.

Model 1: GARCH
```{r,warning=FALSE,tidy=TRUE,message=FALSE}
#All models are actually lists of that model type for each currency
#Daily
garch_daily_n2_1=list()
garch_daily_n2_2=list()
garch_daily_n3_1=list()
garch_daily_n3_2=list()
garch_daily_n3_2=list()
#Weekly
garch_weekly_n2_1=list()
garch_weekly_n2_2=list()
garch_weekly_n3_1=list()
garch_weekly_n3_2=list()
garch_weekly_n3_2=list()

#train_garch_curr trains a garch for one currency 
#data_type is daily / weekly, n_states of number of regimes, reg is the regime number, curr_i is the currency id
train_garch_curr=function(data_type,n_states,reg,curr_i){
  use_data=get(paste(data_type,"_data",sep=""))[[curr_i]]
  use_data=use_data[which(use_data[,"S_train"]==1),]
  states=get(paste(data_type,"states",n_states,sep="_"))[[i]]
  use_data=cbind(use_data,states)
  #State 1 #########
  #Train state 1
  train_1=use_data[which(use_data$states==1),]
  
  #State 2 #########
  #Train state 2 
  train_2=use_data[which(use_data$states==2),]
  #State 3 #########
  if(n_states>2){
    train_3=use_data[which(use_data$states==3),]  
  }
}


garch_stats=function(data_type,curr_i){
  use_data=get(paste(data_type,"_data",sep=""))[[curr_i]]
  train=use_data[which(use_data[,"S_train"]==1),"Ret"]
  test=use_data[which(use_data[,"S_train"]==0),"Vol"]
  model=garchFit(formula=~garch(1,1),data=train,verbose=FALSE)
  pred_y=predict(model,n.ahead=length(test))$standardDeviation
  #Since we have log-vols, but the predictions arent need to change
  pred_y=log(pred_y)
  return(mse(pred_y,test))
}

#Get stats for using just one garch as a baseline comparison
mse_garch_all_daily=sapply(seq(1,length(currencies),1), function(x){ garch_stats("daily",x)})

mse_garch_all_weekly=sapply(seq(1,length(currencies),1), function(x){ garch_stats("weekly",x)})

#Table for presentation - we will overwrite pres_table consistently throughout
#Tables output into Latex
pres_table=cbind(mse_garch_all_daily,mse_garch_all_weekly)
means=c(mean(mse_garch_all_daily),mean(mse_garch_all_weekly))
pres_table=rbind(pres_table,means)
colnames(pres_table)=c("Daily","Weekly")
rownames(pres_table)=c(currencies,"Average")
stargazer(pres_table)



```
