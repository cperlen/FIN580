---
title: "FIN580_HW3"
output: pdf_document
---

#installing needed packages
```{r, warning=FALSE,tidy=TRUE, message=FALSE }
#Setup 
library(e1071)
library(lubridate)
library(tidyverse)
library(gridExtra)
library(xlsx)
library(forecast)
library(tseries)
library(stats)
library(car)
library(glmnet)
library(miscTools)
library(Metrics)
library(knitr)
library(class)
library(vars)
library(stargazer)
library(BigVAR)
library(orderedLasso)
library(BioPhysConnectoR)

#Set seed
set.seed(1560)

```


Reading in and preprocessing data
```{r, warning=FALSE,tidy=TRUE, message=FALSE }

#setwd("~/Desktop/FIN580/data") - Chase's
#setwd("~/Desktop/Grad_School/2016-2017_Spring/Amin/Homework/HW_3/FIN580/data") - Nina's
load_data_from_scratch = F

if(load_data_from_scratch){
  file_names=dir(path="~/Desktop/FIN580/data",pattern = '.csv')
  currencies = strsplit(file_names[1:(length(file_names)-1)],'USD.csv')
  
  labels = read.csv(file_names[length(file_names)],header = T)
  labels[,1] = as.Date(labels[,1], origin = lubridate::origin )
  labels[nrow(labels),2] = 0 #not training on last day because do not have data to test fit
  colnames(labels)[1] = "Date"
  
  prices = lapply(file_names[1:length(currencies)], function(x) { 
    temp = read.csv(x ,header = T)
    temp = temp[,c("Date","Close")]
    if(x == "AUDUSD.csv"){
      temp$Date = as.Date(temp$Date, format = "%m/%d/%y",origin = lubridate::origin) #why it has a different format I have no idea
    }
    else{
      temp$Date = as.Date(temp$Date, format = "%m/%d/%Y",origin = lubridate::origin)
    }
    return(temp) })
  
  names(prices) = currencies
  dates = unique(labels[,1])
  
  #compute return series
  get_5min_rets = function(x){
    tot_rets = data.frame(Date=as.Date(character()), Returns = numeric())
    pos = 1
    for(i in 1:length(dates)){
      indicies = which(x[,1] == dates[i])
      if(length(indicies) != 0){
  
        daily_prices = x[indicies,2]
        daily_rets = log(daily_prices[2:length(daily_prices)]/daily_prices[1:(length(daily_prices)-1)])
        len = length(daily_rets)
        tot_rets[pos:(pos+len-1),] = list(rep(dates[i],length(daily_rets)),daily_rets)
        pos = pos + len
      }
    }
    return(tot_rets)
  }
  
  rets_5min = lapply(prices, get_5min_rets)
  
  get_daily_rets = function(x){
    rets = data.frame(Date=as.Date(character()), Ret = numeric(), Train = numeric() )
    pos = 1
    for(i in 1:length(dates)){
      indicies = which(x[,1] == dates[i])
      len = length(indicies)
      if(len != 0){
        ret = log(x[indicies[len],2]/x[indicies[1],2]) #return for the day is log(P_23:55/P_0:00)
        rets[pos,] = list(dates[i],ret, labels[which(labels$Date == dates[i]),2])
        pos = pos + 1
        }
    }
    return(rets)
  }
  
  daily_rets = lapply(prices, get_daily_rets)
  
  
  
  #compute volatility series

  get_daily_vols = function(x){

    vols = data.frame(Date=as.Date(character()), Vol = numeric(), Train = numeric() )
    pos = 1
    for(i in 1:length(dates)){
      indicies = which(x[,1] == dates[i])
      if(length(indicies) != 0){
          rets = x[indicies,2]
          vol = sqrt(252) * sd(rets) #annualize volatility
          if(vol != 0){ #get rid of days during which vol is 0
            vols[pos,] = list(dates[i],log(vol), labels[which(labels$Date == dates[i]),2])
            pos = pos + 1
        }
      }
    }
    return(vols)
  }
  
  daily_vols = lapply(rets_5min,get_daily_vols)
  
  
  #weekly statics
  dates_by_curr = lapply(daily_vols, function(x){ x$Date}) #which dates have non-zero vols
  
  
  
  get_weekly_vols = function(curr){
    x = rets_5min[[curr]]
    c_dates = dates_by_curr[[curr]]
    
    vols = data.frame(Date=as.Date(character()), Ret = numeric(), Train = numeric() )
    pos = 1
    for(i in 5:length(c_dates)){
      indicies = unique(unlist(sapply((i-4):i, function(j) { which(x[,1] == c_dates[j])})))
      if(length(indicies) != 0){
          rets = x[indicies,2]
          vol = sqrt(50) * sd(rets) #annualize volatility
          if(vol != 0){ #get rid of days during which vol is 0
            vols[pos,] = list(c_dates[i],log(vol), labels[which(labels$Date == c_dates[i]),2])
            pos = pos + 1
        }
      }
    }
    return(vols)
  }
  
  weekly_vols = lapply(currencies, get_weekly_vols)
  names(weekly_vols) = currencies
  
  
  
  get_weekly_rets = function(curr){
    x = prices[[curr]]
    c_dates = dates_by_curr[[curr]]
    
    rets = data.frame(Date=as.Date(character()), Ret = numeric(), Train = numeric() )
    pos = 1
    for(i in 5:length(c_dates)){
      indicies = unique(unlist(sapply((i-4):i, function(j) { which(x[,1] == c_dates[j])})))
      n = length(indicies)
      if(n != 0){
          ret = log(x[indicies[n],2] / x[indicies[1],2] )#last day close divided first day open
          rets[pos,] = list(c_dates[i],ret, labels[which(labels$Date == c_dates[i]),2]) 
          pos = pos + 1
        }
      }
    return(rets)
  }
  
  weekly_rets = lapply(currencies, get_weekly_rets)
  names(weekly_rets) = currencies
  
  save(weekly_rets, file = "weekly_rets.Rdata")
  save(daily_rets,file = "daily_rets.Rdata")
  save(daily_vols,file="daily_vols.RData")
  save(weekly_vols,file="weekly_vols.RData")
  save(currencies, file = "currencies.RData")
}

if(!load_data_from_scratch)  {
  load("daily_vols.RData")
  load("weekly_vols.RData")
  load("daily_rets.RData")
  load("weekly_rets.RData")
  load("currencies.RData")
}
  
  
```


Support Vector Machine implementation: Work in progress I will handle.  Nina take care of logistic regression

```{r}
#intuition for choosing delta grid
train_indicies = which(daily_vols$AUD[,3] == 1)
AUDvols = daily_vols$AUD[,2]
delta = 0.0
for(i in 1:(length(train_indicies)-1)){
  index = train_indicies[i]
  if(AUDvols[index+1] >= AUDvols[index]){
    delta = delta + AUDvols[index+1]/ AUDvols[index] -1
  }
  else{
    delta = delta + 1 - AUDvols[index+1]/ AUDvols[index-1]
  }
}
delta / (length(train_indicies)-1)



#define grid
delta_grid = seq(-.1,.1,.2/25)

```



Fit daily svm
```{r}
#function for svm
get_labels=function(curr){
  training_index = train_indicies[[curr]]
  vol_series = daily_vols[[curr]][,2]
  labels = sapply(training_index, function(i){ 
    if(vol_series[i+1]/vol_series[i] -1 >= delta){
      return(1)
    }
    else{
      return(-1)
    }})
  return(labels)
}

#compute indices of trianing set
train_indicies = sapply(daily_vols,function(x) { which(x[,3] == 1)})
names(train_indicies) = currencies 


#helper function, fits svm to linear vols
delta <<- delta

svm_daily_linear = function(delta,curr){
  
  #computes labels (which depend on delta)
  vols = daily_vols[[curr]]
  train_indices = which(vols[,3] == 1)
  test_indices = which(vols[,3] == 0) 
  test_indicies = test_indicies[1:(length(test_indicies-1))] #do not include last date
  
  #generates model data sets
  train_labels = get_labels(curr) #codes +- 1
  y = as.factor(train_labels)
  x = daily_vols[[curr]][train_indicies,2]
  df = as.data.frame(cbind(x,y))
  names(df) = c("vol","label")
    
  #tune and fit svm 
  svm_tune = tune(svm, train.x=df$vol, train.y=df$label, kernel="linear", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)), type = 'C-classification')
  svm_model = svm(df$label ~ ., data=df,kernel="linear", cost = svm_tune$best.model$cost, gamma = svm_tune$best.model$gamma,type = 'C-classification')

  #regression model
  test_labels = predict(svm_models[[curr]], vols[test_indicies,2]) #svm prediction
  test_predictions = sapply(1:length(test_labels), function(i) {
    if (test_labels[i] == 1){
      return(vols[test_indicies[i]] * (1 + delta)) 
    }
    else{
      return(vols[test_indicies[i]] * (1 - delta)) 
    }
  })
  
  #compute mse
  return( mean( (test_predictions - vols[test_indicies+1,2])^2))
}


```

include plots of data in feature space



Logistic Regression Implementation
```{r,tidy=TRUE,warning=FALSE}
#Since the R lag function doesn't pad with NAs - we write our own lag function
lagpad = function(x, k) {
    if (!is.vector(x)) 
        stop('x must be a vector')
    if (!is.numeric(x)) 
        stop('x must be numeric')
    if (!is.numeric(k))
        stop('k must be numeric')
    if (1 != length(k))
        stop('k must be a single number')
    c(rep(NA, k), x)[1 : length(x)] 
}
#Get lagged data for autoreggressive models
get_lagged_data=function(time_series,max_lag){
  xs=matrix(NA,nrow=length(time_series),ncol=max_lag)
  xs[,1]=lagpad(time_series,1)
  if(max_lag>1){
    xs[,2]=lagpad(time_series,2)
  }
  if(max_lag>2){
    xs[,3]=lagpad(time_series,3)
  }
  return(na.omit(xs))
}
#Data getting function for LR 
#data is list of data frames, i is numeric, train is 1 (for true) or 0 (for false)
get_lr_data=function(data,i,train){
  use_data=data[[i]]
  t1_indices=which(use_data[,"Train"]==train)
  t_indices=t1_indices-1
  ret_data=data.frame(matrix(cbind(use_data[t1_indices,"Vol"],use_data[t_indices,"Vol"]),ncol=2))
  colnames(ret_data)=c("t1","t")
  return(ret_data)
} 


#Optimization of delta for logistic regression over training set

#Fit model for one currency for one delta
#New_data is for prediction
fit_lr=function(use_data,delta,new_data){
  y=sapply(seq(1,nrow(use_data),1), function(i){ 
    if(use_data[i,"t1"]/use_data[i,"t"]-1 >= delta){
      return(1)
    }
    else{
      return(0) #glm() uses 1 or 0 shouldnt matter since we already labeled y based on its being -1 or 1
    }})
  use_data=cbind(y,use_data,use_data[,"t"]*delta)
  colnames(use_data)=c(colnames(use_data[,1:3]),"t1del")
  model=glm(formula=as.formula("y~(t1-t)/(t1del)"),family=binomial(link="logit"),data=use_data)
  new_data=cbind(use_data,use_data[,"t"]*delta)
  pred_y=predict(model,type="response",newdata=new_data)
  pred_sigs=sapply(seq(1,length(y),1),function(i){
    if(round(y[i],0)==1){
      return(new_data[i,"t"]*(1+delta))
    }
    else{
      return(new_data[i,"t"]*(1-delta))
    }
    
  })


#Sequence of deltas to use
deltas=seq(0,0.15,length.out=10)
#Will save mse by delta by currency just in case we want to get fancy and plot that, but probs not gonna happen tbh 
mses_d=data.frame(matrix(NA,ncol=length(currencies),nrow=length(deltas)))
colnames(mses_d)=currencies
rownames(mses_d)=round(deltas,2)
mses_w=data.frame(matrix(NA,ncol=length(currencies),nrow=length(deltas)))
colnames(mses_w)=currencies
rownames(mses_w)=round(deltas,2)
#Daily - train
for(i in 1:length(currencies)){
  u_d=get_lr_data(daily_vols,i,1)
  mses_d[,i]=sapply(deltas,function(x){fit_lr(u_d,x,u_d)}) #newdata = usedata=train
}

min_del_d=deltas[which.min(rowMeans(mses_d))]

#Weekly - train
for(i in 1:length(currencies)){
  u_d=get_lr_data(weekly_vols,i,1)
  mses_w[,i]=sapply(deltas,function(x){fit_lr(u_d,x,u_d)}) #newdata = usedata=train
}

stargazer(mses_d,summary=FALSE)
stargazer(mses_w,summary=FALSE)

#Plot MSES vs. Delta - training data
plot(deltas,rowMeans(mses_d),pch=23,col=2,main="Training MSE by Delta - Daily Vols",xlab="Delta",ylab="MSE over training data")
dev.copy(pdf,"lr_daily_train.pdf")
dev.off()
plot(deltas,rowMeans(mses_w),pch=2,col=3,main="Training MSE by Delta - Weekly Vols",xlab="Delta",ylab="MSE over training data")
dev.copy(pdf,"lr_weekly_train.pdf")
dev.off()

#Testing mses - we'll combine weekly and daily
mses_test=data.frame(matrix(NA,ncol=length(currencies)+1,nrow=2))
colnames(mses_test)=c(currencies,"Average")
rownames(mses_test)=c("Daily Testing","Weekly Testing")
for(i in 1:length(currencies)){
  u_d=get_lr_data(daily_vols,i,1)
  n_d=get_lr_data(daily_vols,i,0)
  mses_test[1,i]=fit_lr(u_d,min_del_d,n_d)
  u_d=get_lr_data(daily_vols,i,1)
  n_d=get_lr_data(daily_vols,i,0)
  mses_test[2,i]=fit_lr(u_d,min_del_w,n_d)
}
mses_test[,ncol(mses_test)]=rowMeans(mses_test[,1:9])
stargazer(t(mses_test),summary=FALSE,rownames=TRUE)

```
