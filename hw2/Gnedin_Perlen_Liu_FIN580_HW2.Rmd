---
title: "Gnedin_Perlen_Liu_FIN580_HW2"
author: "Gnedin_Perlen_Liu"
date: "March 8, 2017"
output: pdf_document
---
This is the latest version. 
```{r,tidy=TRUE}
#Setup 
library(gridExtra)
library(xlsx)
library(forecast)
library(tseries)
library(stats)
library(car)
library(glmnet)
library(miscTools)
library(Metrics)
library(knitr)
library(class)
library(vars)
library(BigVAR)
library(orderedLasso)
library(BioPhysConnectoR)

#Set seed
set.seed(1560)

```

Read in data. There might some days the price remains constant. You should check the data and delete those days, since the estimate of volatility will be zero.  

Note: You will have to change the paths to read in on your own computer

  
  Reading in and preprocessing data
```{r, warning=FALSE,tidy=TRUE, message=FALSE }

#setwd("~/Desktop/FIN580/data")
setwd("~/Desktop/Grad_School/2016-2017_Spring/Amin/Homework/HW_3/FIN580/data") #Nina's
load_data_from_scratch = T

if(load_data_from_scratch){
  file_names=dir(path="~/Desktop/FIN580/data",pattern = '.csv')
  currencies = strsplit(file_names[1:(length(file_names)-1)],'USD.csv')
  labels = read.csv(file_names[length(file_names)],header = T)
  labels[,1] = as.Date(labels[,1], origin = lubridate::origin )
  labels[nrow(labels),2] = 0 #not training on last day because do not have data to test fit
  colnames(labels)[1] = "Date"
  
  prices = lapply(file_names[1:length(currencies)], function(x) { 
    temp = read.csv(x ,header = T)
    temp = temp[,c("Date","Close")]
    if(x == "AUDUSD.csv"){
      temp$Date = as.Date(temp$Date, format = "%m/%d/%y",origin = lubridate::origin) #why it has a different format I have no idea
    }
    else{
      temp$Date = as.Date(temp$Date, format = "%m/%d/%Y",origin = lubridate::origin)
    }
    return(temp) })
  
  names(prices) = currencies
  dates = unique(labels[,1])
  
  #compute return series
  get_5min_rets = function(x){
    tot_rets = data.frame(Date=as.Date(character()), Returns = numeric())
    pos = 1
    for(i in 1:length(dates)){
      indicies = which(x[,1] == dates[i])
      if(length(indicies) != 0){
        
        daily_prices = x[indicies,2]
        daily_rets = log(daily_prices[2:length(daily_prices)]/daily_prices[1:(length(daily_prices)-1)])
        len = length(daily_rets)
        tot_rets[pos:(pos+len-1),] = list(rep(dates[i],length(daily_rets)),daily_rets)
        pos = pos + len
      }
    }
    return(tot_rets)
  }
  
  rets_5min = lapply(prices, get_5min_rets)
  
  get_daily_rets = function(x){
    rets = data.frame(Date=as.Date(character()), Ret = numeric(), Train = numeric() )
    pos = 1
    for(i in 1:length(dates)){
      indicies = which(x[,1] == dates[i])
      len = length(indicies)
      if(len != 0){
        ret = log(x[indicies[len],2]/x[indicies[1],2]) #return for the day is log(P_23:55/P_0:00)
        rets[pos,] = list(dates[i],ret, labels[which(labels$Date == dates[i]),2])
        pos = pos + 1
      }
    }
    return(rets)
  }
  
  daily_rets = lapply(prices, get_daily_rets)
  
  
  
  #compute volatility series
  
  get_daily_vols = function(x){
    
    vols = data.frame(Date=as.Date(character()), Vol = numeric(), Train = numeric() )
    pos = 1
    for(i in 1:length(dates)){
      indicies = which(x[,1] == dates[i])
      if(length(indicies) != 0){
        rets = x[indicies,2]
        vol = sqrt(252) * sd(rets) #annualize volatility
        if(vol != 0){ #get rid of days during which vol is 0
          vols[pos,] = list(dates[i],log(vol), labels[which(labels$Date == dates[i]),2])
          pos = pos + 1
        }
      }
    }
    return(vols)
  }
  
  daily_vols = lapply(rets_5min,get_daily_vols)
  
  
  #weekly statics
  dates_by_curr = lapply(daily_vols, function(x){ x$Date}) #which dates have non-zero vols
  
  
  
  get_weekly_vols = function(curr){
    x = rets_5min[[curr]]
    c_dates = dates_by_curr[[curr]]
    
    vols = data.frame(Date=as.Date(character()), Ret = numeric(), Train = numeric() )
    pos = 1
    for(i in 5:length(c_dates)){
      indicies = unique(unlist(sapply((i-4):i, function(j) { which(x[,1] == c_dates[j])})))
      if(length(indicies) != 0){
        rets = x[indicies,2]
        vol = sqrt(50) * sd(rets) #annualize volatility
        if(vol != 0){ #get rid of days during which vol is 0
          vols[pos,] = list(c_dates[i],log(vol), labels[which(labels$Date == c_dates[i]),2])
          pos = pos + 1
        }
      }
    }
    return(vols)
  }
  
  weekly_vols = lapply(currencies, get_weekly_vols)
  names(weekly_vols) = currencies
  
  
  
  get_weekly_rets = function(curr){
    x = prices[[curr]]
    c_dates = dates_by_curr[[curr]]
    
    rets = data.frame(Date=as.Date(character()), Ret = numeric(), Train = numeric() )
    pos = 1
    for(i in 5:length(c_dates)){
      indicies = unique(unlist(sapply((i-4):i, function(j) { which(x[,1] == c_dates[j])})))
      n = length(indicies)
      if(n != 0){
        ret = log(x[indicies[n],2] / x[indicies[1],2] )#last day close divided first day open
        rets[pos,] = list(c_dates[i],ret, labels[which(labels$Date == c_dates[i]),2]) 
        pos = pos + 1
      }
    }
    return(rets)
  }
  
  weekly_rets = lapply(currencies, get_weekly_rets)
  names(weekly_rets) = currencies
  
  append_target = function(ts){
    for(curr in currencies){
      temp = ts[[curr]]
      len = nrow(ts[[curr]])
      ts[[curr]] = ts[[curr]][1:(len-1),]
      ts[[curr]] [,'Target'] = temp[2:len,2] 
    }
    return(ts)
  }
  
  append_ret = function(ts,rets){
    for(curr in currencies){
      dates = ts[[curr]]$Date
      ret = rets[[curr]]
      pos = 1
      for(d in dates){
        lookup = which(ret[,1]== as.Date(d,lubridate::origin))
        ts[[curr]][pos,'Ret'] = ret$Ret[lookup]
        pos = pos + 1
      }
    }
    return(ts)
  }
  
  append_label = function(ts,rets){
    for(curr in currencies){
      series = ts[[curr]]
      labels = sapply(1:nrow(series),function(i){
        s = sign(series$Target[i] - series$Vol[i])
        if(s == 0){ #break ties
          s = 1
        }
        return(s)} )
      ts[[curr]]['Y(t)'] = labels
    }
    return(ts)
  }
  
  
  daily_data = append_target(daily_vols)
  weekly_data = append_target(weekly_vols)
  daily_data = append_ret(daily_data,daily_rets)
  weekly_data = append_ret(weekly_data,weekly_rets)
  daily_data = append_label(daily_data)
  weekly_data = append_label(weekly_data)
  
  #remove JPY and SEK
  currencies = currencies[-6] 
  currencies = currencies[-8]
  weekly_data = weekly_data[-6]
  weekly_data = weekly_data[-8]
  daily_data = daily_data[-6]
  daily_data = daily_data[-8]
  
  save(weekly_data, file = "weekly_data.Rdata")
  save(daily_data,file = "daily_data.Rdata")
  save(currencies, file = "currencies.RData")
}

if(!load_data_from_scratch)  {
  load("weekly_data.Rdata")
  load("daily_data.Rdata")
  load("currencies.RData")
}
```


Get volatilities, annualize, and take the log. Fix windows.
```{r,tidy=TRUE}
period=288 #Only using daily vols for this assignment
get_vol=function(time_series,start_i,end_i){
  use_data=time_series[start_i:end_i,]
  sds=apply(use_data,2,sd)*sqrt(period*252)
  return(sds)
}
vols=data.frame(matrix(NA,ncol = ncol(data),nrow=nrow(data)/period))
vols=sapply(seq(1,nrow(data)-period,period),function(x) {get_vol(data,x,x+288)})
#Transpose to keep columns and currencies
vols=t(vols)
#Change to log vols
vols=log(vols)


save(vols,file="vols.RData")
load("vols.RData")

```

Here we split our data into training and test. Since we use VAR models we will split our data sequentially. We will aim to use 2/3 of the data for the training set, and 1/3 for the testing.
```{r,tidy=TRUE}
split=floor(nrow(vols)*(3.5/5))
train=vols[1:split,]
test=vols[(split+1):nrow(vols),]
save(train,file="train.RData")
save(test,file="test.RData")
```


General functions to be used across models. 
```{r,tidy=TRUE}
#Since the R lag function doesn't pad with NAs - we write our own lag function
lagpad = function(x, k) {
    if (!is.vector(x)) 
        stop('x must be a vector')
    if (!is.numeric(x)) 
        stop('x must be numeric')
    if (!is.numeric(k))
        stop('k must be numeric')
    if (1 != length(k))
        stop('k must be a single number')
    c(rep(NA, k), x)[1 : length(x)] 
}
#Get lagged data for autoreggressive models
get_lagged_data=function(time_series,max_lag){
  xs=matrix(NA,nrow=length(time_series),ncol=max_lag)
  xs[,1]=lagpad(time_series,1)
  if(max_lag>1){
    xs[,2]=lagpad(time_series,2)
  }
  if(max_lag>2){
    xs[,3]=lagpad(time_series,3)
  }
  return(na.omit(xs))
}
```

VAR model (non lasso).
```{r,tidy=TRUE}
ps=c(1,2,3)
colnames(train)=seq(1,ncol(train),1) #VAR cares about col names for some reason
fit_VAR=function(p){
  model=VAR(train,p=p)
  pred=predict(model,n.ahead=nrow(train))
  all=pred[[1]]
  data=all[[1]][,1]
  for(i in 2:ncol(test)){
    temp=all[[i]][,1]
    data=cbind(data,temp)
  }
  errs=(data-train)^2
  return(errs)
}

var_mses=list()
for(i in 1:length(ps)){
  var_mses[[i]]=fit_VAR(i)
}

#Plotting
plot_data=matrix(NA,nrow=3,ncol=ncol(test))
for(i in 1:ncol(test)){
  plot_data[1,]=mean(var_mses[[1]][,i])
  plot_data[2,]=mean(var_mses[[2]][,i])
  plot_data[3,]=mean(var_mses[[3]][,i])
}

matplot(plot_data,main="VAR model MSE by lag",xlab="Lag",ylab="MSE")
legend("bottom",legend=names,col=1:9,pch=1,ncol = 3,xpd = TRUE, text.width=c(0.4,0.4,0.4,0.4))
dev.copy(pdf,"Var model MSE by lag.pdf")
dev.off()

```
LASSO described in [1].  You are expected to run one regression with the whole training history ( rst 3.5 years) for each λ. Run the regressions with different λs and plot the  in sample  Mean Square Error (MSE) with respect to the λ. Use the best λ (corresponds to the lowest MSE) in the test sample to report the  nal evaluation numbers.
```{r,tidy=TRUE}
#Available lags
ps=c(1,2,3)

#VAR lasso
lams_opt_VAR_l=c()
fit_VAR_lasso=function(p){
  model=constructModel(data.matrix(train),p=p,"Basic",gran=c(50,10),h=1)
  res=cv.BigVAR(model)
  o_lam=res@OptimalLambda
  mse_in=res@InSampMSFE
  name=paste("VAR Lasso Results Lag",p)
  #Plot and save as pdf
  plot(res)
  title(main = name)
  #Save as pdf 
  dev.copy(pdf,paste(name,".pdf",sep=""))
  dev.off()
  return(list(o_lam,mse_in))
}

for(i in 1:length(ps)){
  temp=fit_VAR_lasso(i)
  lams_opt_VAR_l=append(lams_opt_VAR_l,temp[[1]])
}

#Expanding window fits of VAR lasso models using the optimal lambda to get 1 step predictions
#Prediction function - returns MSE for 1 prediction over all currencies
pred_var_lasso=function(data,lam,p,ans){
  model=constructModel(data.matrix(data),p=p,"Basic",ownlambdas=TRUE,gran=lam,h=1,verbose=FALSE)
  res=cv.BigVAR(model)
  pred=t(predict(res,1))
  return(mean((matrix(ans,nrow=1)-pred)^2))
}

#Returns more detailed statistics - currency by currency
pred_var_lasso_det=function(data,lam,p,ans){
  model=constructModel(data.matrix(data),p=p,"Basic",ownlambdas=TRUE,gran=lam,h=1,verbose=FALSE)
  res=cv.BigVAR(model)
  pred=t(predict(res,1))
  return((matrix(ans,nrow=1)-pred)^2)
}

#Non detailed
temp=seq(1,nrow(test)-2,1)
mses_var_lasso=data.frame(matrix(NA,nrow=(length(temp)+1),ncol=3))

for(i in 1:length(ps)){
  lam=lams_opt_VAR_l[i]
  mses_var_lasso[1,i]=pred_var_lasso(train,lam,i,test[1,])
  mses_var_lasso[2:nrow(mses_var_lasso),i]=sapply(temp,function(x){print(x) 
    pred_var_lasso(rbind(train,test[1:(x-1),]),lam,i,test[x+1,])})
}

save(mses_var_lasso,file="mses_var_lasso.RData")
load("mses_var_lasso.RData")

#Plot and sae
plot(colMeans(mses_var_lasso),main="VAR Lasso Model Training MSE by Lag",xlab="Lag",ylab="MSE",pch=24,col=2)
dev.copy(pdf,"var_lasso_test_mse.pdf")
dev.off()

#Detailed

mse_var_lasso_det_data=list()

mses_var_lasso_det_1=data.frame(matrix(NA,nrow=(length(temp)+1),ncol=9))
mses_var_lasso_det_2=data.frame(matrix(NA,nrow=(length(temp)+1),ncol=9))
mses_var_lasso_det_3=data.frame(matrix(NA,nrow=(length(temp)+1),ncol=9))

i=1
lam=lams_opt_VAR_l[i]
mses_var_lasso_det_1[1,]=pred_var_lasso_det(train,lam,i,test[1,])
mses_var_lasso_det_1[2:nrow(mses_var_lasso_det),]=sapply(temp,function(x){pred_var_lasso_det(rbind(train,test[1:(x-1),]),lam,i,test[x+1,])})
i=2
lam=lams_opt_VAR_l[i]
mses_var_lasso_det_2[1,]=pred_var_lasso_det(train,lam,i,test[1,])
mses_var_lasso_det_2[2:nrow(mses_var_lasso_det),]=sapply(temp,function(x){pred_var_lasso_det(rbind(train,test[1:(x-1),]),lam,i,test[x+1,])})
i=3
lam=lams_opt_VAR_l[i]
mses_var_lasso_det_3[1,]=pred_var_lasso_det(train,lam,i,test[1,])
mses_var_lasso_det_3[2:nrow(mses_var_lasso_det),]=sapply(temp,function(x){pred_var_lasso_det(rbind(train,test[1:(x-1),]),lam,i,test[x+1,])})
  
 

save(mses_var_lasso_det,file="mses_var_lasso_det.RData")

mses_var_lasso_det_df=data.frame(matrix(NA,ncol=9*3,nrow=length(mse_var_lasso_det_data)/3))
for(i in  1:length(mse_var_lasso_det_data)/3){
  for(j in 1:(3*9)){
    mses_var_lasso_det_df[i,j]=mse_var_lasso_det_data[i+j-1]
  }
}

names=c("AUD","CAD","CHF","EUR","GBP","JPY","NOK","NZD","SEK")

barplot(colMeans(mses_var_lasso_det_1),pch=1,col=1:9,main="Average MSE by currency for 1-lag VAR lasso",ylab="Ave MSE by currency",names.arg=names,cex.names=0.8)
dev.copy(pdf,"var_lasso_mse_curr.pdf")
dev.off()

barplot(colMeans(mses_var_lasso_det_2),pch=1,col=1:9,main="Average MSE by currency for 2-lag VAR lasso",ylab="Ave MSE by currency",names.arg=names,cex.names=0.8)
dev.copy(pdf,"var_lasso_mse_curr2.pdf")
dev.off()


```

$\textbf{Ordered lasso implementation}$
Here we fit the ordered LASSO for extra credit. 
```{r,tidy=TRUE}

#Fits lasso based on lag 
#Can also do ordered lasso based on order parameter
fit_lasso=function(col_i,max_lag,lam,order){
  ts=train[,col_i]
  ts=ts[which(ts!=0)]
  y=matrix(ts[(max_lag+1):length(ts)])
  x=get_lagged_data(ts,max_lag)
  model=orderedLasso(x,y,lambda = lam,strongly.ordered = order)
  pred_train=predict(model,x)$yhat
  new_ts=test[,col_i]
  new_ts=new_ts[which(new_ts!=0)]
  new_y=matrix(new_ts[(max_lag+1):length(new_ts)])
  new_x=get_lagged_data(new_ts,max_lag)
  pred_test=predict(model,new_x)$yhat
  return(list(mse(pred_train,y),mse(pred_test,new_y)))
}

#Getting range of lambdas
lam_1=0
#Get lam_L - maximum lambda, shrinks all parameters to 0 - based on most complex model (p=3)
currs=seq(1,ncol(train),1)
max_lag=max(ps)
get_max_L=function(col_i){
  ts=train[,col_i]
  ts=ts[which(ts!=0)]
  y=matrix(ts[(max_lag+1):length(ts)])
  x=get_lagged_data(ts,3)
  cv=cv.glmnet(x,y)
  return(cv$lambda[1])
}
max_L=sapply(currs,get_max_L)
lam_L=max(max_L)
lams=seq(0,lam_L,length.out = 10)

#Mses is a list - train first, test second
populate_tables=function(p,order){
  mse_train=matrix(NA,ncol=ncol(vols),nrow=length(lams))
  mse_test=matrix(NA,ncol=ncol(vols),nrow=length(lams))
  for(i in 1:ncol(mse_train)){
  temp=sapply(lams,function(x) fit_lasso(i,p,x,order))
  mse_train[,i]=matrix(unlist(temp[1,]),ncol=1)
  mse_test[,i]=matrix(unlist(temp[2,]),ncol=1)
  }
  return(list(mse_train,mse_test))
}

#Getting all MSE tables for ordered lasso - note we exclude 1lag as this is not a VAR model
for(i in 2:length(ps)){
  p=ps[i]
  name_train=paste("train_ordered_",p,sep="")
  name_test=paste("test_ordered_",p,sep="")
  temp=populate_tables(p,TRUE)
  assign(name_train,temp[1])
  assign(name_test,temp[2])
}
```

Plot MSEs by lambda for ordered Lasso.
```{r,tidy=TRUE}
#Get average MSEs by lambda (for plotting)
ave_mse_train=matrix(1,nrow=length(lams),ncol=length(ps))
ave_mse_test=matrix(1,nrow=length(lams),ncol=length(ps))

for(i in 1:length(ps)){
  name_train=paste("train_ordered_",p,sep="")
  name_test=paste("test_ordered_",p,sep="")
  use_train=matrix(unlist(get(name_train)),ncol=ncol(vols))
  use_test=matrix(unlist(get(name_test)),ncol=ncol(vols))
  ave_mse_train[,i]=rowMeans(use_train)
  ave_mse_test[,i]=rowMeans(use_test)
}

#PLotting
matplot(lams,ave_mse_train,type=c("b"),pch=1,col=1:3,main="Training MSEs by lambda",xlab="Lambdas",ylab="Ave MSE over all currencies")
legend("topright",legend=1:3,col=1:3,pch=1)
dev.copy(pdf,"Training MSES by lambda - ordered lasso")
dev.off()
  
matplot(lams,ave_mse_test,type=c("b"),pch=1,col=1:3,main="Testing MSEs by lambda",xlab="Lambdas",ylab="Ave MSE over all currencies")
legend("topright",legend=1:3,col=1:3,pch=1)
dev.copy(pdf,"Testing MSES by lambda - ordered lasso")
dev.off()

```



KNN method we’ve covered during class. Features and Labels First, you should use today’s vol t as the 1-dimensional feature space, which means $x_t = \sigma_t$. The label is just what you want to forecast, which means $y_t = \sigma_{t+1}$. Note that you can choose different k for KNN, such as k = {1, 3, 5, 10, 20, 50}.

Training Sample: For each day/week/month, we can either use expanding window, that means use all the data up to that date as training sample to find the k-nearest points, or you can use rolling window, that means, fix the look-back window when training your model, say for each day, you can always lookback
for 2 years as training sample.

KNN regression Based on your feature space and training sample, once you found your k-nearest points to
$x_t$ = $\sigma_t$, you can use the KNN regression we’ve covered in class (details can be found in course notes) to build a forecast for $y_t = \sigma_{t-1}$


```{r,tidy=TRUE}
#helper functions

#implements k-nearest neighbors regression on some time series ts, lambda is penalty for time, lookBack is number of data points to consider
#we used expanding window

comp_distance = function(x){
  return((x[1]-origin[1])^2  + lam* (x[2]-origin[2])^2)
}

get_knn = function(center,slice,k){
    origin <<- center
    dist = apply(slice,1,comp_distance)
    sorted = sort(dist,decreasing=F)[1:k]
    indicies = sapply(seq(1,k), function(x) {which(dist == sorted[x])})
    
    #indicies = c()
    #for(j in 1:k){
    # indicies[j] = which(dist == sorted[j]) 
    #}
    slice[length(slice) + 1] = origin[1]
    return(slice[indicies+1]) #get what happened the next day
}
#function for fitting on training data
knn_regression = function(ts,k,lambda,lookBack){ 
  START = 100
  lam <<- lambda
  time = c(seq(1,length(ts),1))
  ts = cbind(ts, time)
  regressors = matrix(nrow = nrow(ts)-START,ncol = k)
  y = c()
  for(i in START:(nrow(ts)-1)){
    lag = min(i,lookBack)
    regressors[i-START+1,] = get_knn(ts[i,],ts[(i-lag):(i-1),],k)
    y[i-START+1] = ts[i+1,1] #next days vol 
  }
  model = lm(y ~ 0 + regressors, data = as.data.frame(regressors))
  assign(paste("model_",k,sep = ""), model, globalenv()) #no intercept!
  #assign(paste("model_", currency, "_",k,sep = ""), model, globalenv()) #no intercept!
  return( 1.0/length(y) *   sum((model$fitted.values - y)^2)) #training mse
}

#testing diagnostics
knn_test_diag = function(ts,k,lambda,lookBack){
  START = 910
  lam <<- lambda
  time = c(seq(1,length(ts),1))
  ts = cbind(ts, time)
  regressors = matrix(nrow = nrow(ts)-START,ncol = k)
  y = c()
  for(i in START:(nrow(ts)-1)) {
    lag = min(i,lookBack)
    get_knn(ts[i,],ts[(i-lag):(i-1),],k)
    regressors[i-START+1,] = get_knn(ts[i,],ts[(i-lag):(i-1),],k)
    y[i-START+1] = ts[i+1,1] #next days vol 
  } 
  #model = get(paste("model_",curr,"_",k,sep = ""))
  model = get(paste("model_",k,sep = ""))
  fitted = model$coefficients %*% t(as.data.frame(regressors))
  return( 1.0/length(y) * sum((fitted - y)^2)) #testing mse
}


```



Fit knn regression and choose k on testing
```{r,tidy = TRUE}
ks= seq(1,20,1)
tot_data = rbind(train,test)

model_coef = vector("list", ncol(train))
training_mse = matrix(nrow = length(ks),ncol = ncol(train))
testing_mse = matrix(nrow = length(ks),ncol = ncol(tot_data))

for(curr in 1:ncol(train)){
  model_coef[[curr]] = matrix(0,nrow = length(ks),ncol = length(ks))
  for(k in ks){
    #currency <<- curr
    training_mse[k,curr] = knn_regression(train[,curr],k,0,nrow(tot_data))
    testing_mse[k,curr] = knn_test_diag(tot_data[,curr],k,0,nrow(tot_data))
    model_coef[[curr]][k,1:k] = get(paste("model_",k,sep=""))$coefficients
  }
}

k_opt = c()
for(i in 1:ncol(train)){
  k_opt[i] = which.min(testing_mse[,i])
}

tot_mse = rep(0,20)
for(i in 1:ncol(train)){
  tot_mse = tot_mse+ testing_mse[,i]
}


k_robust = which.min(tot_mse)

```



Plotting diagnostics
```{r, tidy = TRUE}

currencies = c("AUD","CAD","CHF","EUR","GBP","JPY","NOK","NZD","SEK")
for(i in 1:ncol(train)){
  name = paste("Training MSE v k for for ", currencies[i], sep = "")
  plot(ks,training_mse[,i],main = name, ylab = "MSE", xlab = "k", pch=21,  bg="blue")
  dev.copy(pdf,paste(name,".pdf",sep=""))
  dev.off()
  name = paste("Testing MSE v k for ", currencies[i], sep = "")
  plot(ks,testing_mse[,i],main = name, ylab = "MSE", xlab = "k", pch=21,  bg="blue")
  points(k_opt[i],tot_mse[k_opt[i]], bg = 'red')
  dev.copy(pdf,paste(name,".pdf",sep=""))
  dev.off()
}

name = "Aggregate Testing MSE v k"
plot(ks,tot_mse, main = name, ylab = "MSE", xlab = "k",, pch=21,  bg="blue")
points(k_robust,tot_mse[k_robust], pch=21,  bg="red")
dev.copy(pdf,paste(name,".pdf",sep=""))
dev.off()

#plot the coefficients, shows that knn is not good for this purpose
for(i in 1:ncol(train)){
  for(k in ks){
    name =  paste("Coefficients for ", k, "-NN for ", currencies[i], sep = "")
    plot(ks[1:k],model_coef[[i]][k,1:k], main =name, ylab = "Coefficient Size", xlab = "ith nearest neighbor", pch=21,  bg="blue")
    dev.copy(pdf,paste(name,".pdf",sep=""))
    dev.off()
    
  }
}
for(i in 1:ncol(train)){
  name =  paste("Sum of Coefficients v k for ", currencies[i], sep = "")
  sum_coef =  apply(model_coef[[i]],1,sum)
  plot(ks[1:k],sum_coef, main =name, ylab = "Sum", xlab = "k", pch=21,  bg="blue")
  dev.copy(pdf,paste(name,".pdf",sep=""))
  dev.off()
}

```



Research problem, added cost to knn, grid search over c to find optimal cost

```{r, tidy = TRUE}

#cost implementation
cs = seq(0,.4, .4/10) #for c>.4 it takes the nearest k as cost is too high
ks = c(1,3,6,9,12,16,20)
c_training_mse = vector("list", ncol(train))
c_testing_mse = vector("list", ncol(train))
c_model_coef = vector("list", ncol(train))

for(curr in 1:ncol(train)){
    c_testing_mse[[curr]] = matrix(0,nrow = length(ks),ncol = length(cs))  
    c_training_mse[[curr]] = matrix(0,nrow = length(ks),ncol = length(cs))
    c_model_coef[[curr]] = vector("list", length(cs))
  for(i in 1:length(cs)){
     c_model_coef[[curr]][[i]] = matrix(0,nrow = length(ks),ncol = ks[length(ks)])
     
    for(j in 1:length(ks)){
      c_training_mse[[curr]][j,i] = knn_regression(train[,curr],ks[j],cs[i],nrow(tot_data))
      c_testing_mse[[curr]][j,i] = knn_test_diag(tot_data[,curr],ks[j],cs[i],nrow(tot_data))
      c_model_coef[[curr]][[i]][j,1:ks[j]] = get(paste("model_",ks[j],sep=""))$coefficients 
    }
  }
}

```


Plotting and diagnostics for cost
```{r,tidy = TRUE}

#find optimal cost
tot_mse_cost = matrix(0,nrow = length(ks),ncol = length(cs))
for(i in 1:ncol(train)){
  tot_mse_cost = tot_mse_cost + c_testing_mse[[i]]
}



opt_ck = as.data.frame(which(tot_mse_cost == min(tot_mse_cost), arr.ind = TRUE))
colnames(opt_ck) = c("k","c")
opt_ck$k = ks[opt_ck$k]
opt_ck$c = cs[opt_ck$c]

tot_mse_k = c()
for(i in 1:length(ks)){
  tot_mse_k[i] = min(tot_mse_cost[i,])
}

name = "Aggregate Testing MSE v k with time factor"
plot(ks,tot_mse_k, main = name, xlab = "k",ylab = "MSE", pch=21,  bg="blue")
points(opt_ck$k,tot_mse_k[which(ks == opt_ck$k)], pch = 21, bg="red")
dev.copy(pdf,paste(name,".pdf",sep=""))
dev.off()

#make chart

results = matrix(nrow = ncol(train),ncol = 2 )
colnames(results) = c("mse","mse_time") 
rownames(results) = currencies

for(i in 1:ncol(train)){
  results[i,1] = min(testing_mse[,i])
  results[i,2] = min(c_testing_mse[[i]])
}

pdf("knn_results.pdf", height=11, width=8.5)
grid.table(results)
dev.off()

```



#note code has revolving window implementation, can explore for future research